{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and preparation\n",
    "In this notebook, you will look at the data and create a subset of that data. The dataset was \"relatively\" clean upon download, but the lecturers got rid of some pesky delimiter issues. If you want to encounter these issues yourself, you can use the original dataset found at the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the data\n",
    "Load the three datasets and explore the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the data\n",
    "Check if all reviews are connected to a book. Is there a review but no book or user connected to this review? Check if all the authors are spelled correctly, etc etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Subsetting the data\n",
    "The publication accompanied with this dataset [Improving Recommendation Lists Through Topic Diversification](http://www2.informatik.uni-freiburg.de/~cziegler/BX/WWW-2005-Preprint.pdf) by Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen; describes the process of subsetting (condensation steps) the dataset as follows (p5): \n",
    "\n",
    "> Hence, we discarded all books missing taxonomic descriptions, along with all ratings referring to them. Next, we also removed book titles with fewer than 20 overall mentions. Only community members with at least five ratings each were kept. \n",
    "\n",
    "Explore what these parameters mean for the overall dataset. Also, consider if you want the implicit ratings (Book-Rating == 0) in the final dataset. What would the implications be? Would you exclude it before the other parameters, or would you exclude them afterwards? \n",
    "\n",
    "While the publication describes the resulting dataset's dimensions, your results might differ. But that is ok for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra step\n",
    "Take a closer look at `BX-Books.csv` and search for a book named _Robots and Empire_ by Isaac Asimov. What do you encounter? Is this something you would solve? \n",
    "\n",
    "Let us argue that this is problematic for our dataset. How would you solve this? You might want to redo step 2 if you choose to take this extra step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the new dataset(s)\n",
    "Save the dataset(s) in distinct named CSV-files for later usage. Move the file(s) to the data directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
