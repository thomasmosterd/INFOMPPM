{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with NER\n",
    "In this Notebook you will use basic NER to extract possible interesting metadata. We will use the movies dataset from IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# use displacy to visually show the entities. \n",
    "from spacy import displacy\n",
    "\n",
    "# load spacy model. Alternatively you can use en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# load the data\n",
    "df_movies = pd.read_csv('data/imdb.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data inspection\n",
    "Take a look at the movie 'Lawrence of Arabia'. Which genres are connected with this movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[df_movies['Title'] == 'Lawrence of Arabia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the plot of the movie Lawrence of Arabia\n",
    "\n",
    "# code goes here\n",
    "\n",
    "# parse the text through Spacy NLP\n",
    "doc = nlp(plot)\n",
    "\n",
    "# render the text\n",
    "displacy.render(doc, style=\"ent\")\n",
    "\n",
    "# alternative output:\n",
    "# for ent in doc.ents:\n",
    "#   print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare the output\n",
    "Compare the output of Displacy with the tags associated with the movie. What do you notice? Would you include entities from Spacy to the metadata?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process\n",
    "Now it is time to process everything. Create a new column `plot_entities` and process the items by applying the provided function below on the `Plot` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "  # there are some pesky NaN in the data. Easy but not so elegant way to fix this.\n",
    "  if pd.isna(x) == False:\n",
    "    doc = nlp(x)\n",
    "  else:\n",
    "    doc = ''\n",
    "  return doc\n",
    "  \n",
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract a specific entitity\n",
    "Now we are going to create a column `events` to extract EVENTS. Apply the provided function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(x):\n",
    "  events = []\n",
    "  if x != '':\n",
    "    for entities in x.ents:\n",
    "      if entities.label_ == 'EVENT':\n",
    "        events.append(entities.text)\n",
    "  return events\n",
    "\n",
    "# code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inspect the results\n",
    "Now we have an extra column with a list of events it is time to count the events. A simple approach is to create a new dataframe where every row is an item of the list. Save the output to a CSV or other format to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observable is that an event such as _The Second World War_ is referred to in different ways: World War II or WWII. Time to clean up the data and create uniform concepts for events. Export the list from time to time to see the changes. You will notice that many movies are labelled as `war` but do not mention which war, so data cleaning is necessary. Use the function below to clean up the dataset iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_entity(x, value, entities):\n",
    "  return [value if i in entities else i for i in x]  \n",
    "\n",
    "entities = ['WWII']\n",
    "value = 'World War II'\n",
    "\n",
    "df_movies['events'] = df_movies['events'].apply(lambda x: change_entity(x, value, entities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create metadata\n",
    "Now you have a simple way to extract entities which in turn could serve as meta data it is time to create more columns. Which new columns can you think of? Take a look at [Extend Named Entity Recogniser (NER) to label new entities with spaCy](https://towardsdatascience.com/extend-named-entity-recogniser-ner-to-label-new-entities-with-spacy-339ee5979044) to see the different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Finally\n",
    "Which similarity or clustering algorithm would you use in order to make use of the meta data?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
