{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract search results with BeautifulSoup: PBS.org - part 01\n",
    "Now that you have a basic understanding of extracting data of a single page we will continue with extracting search results to extract multiple pages. In this Notebook we will take a look at:\n",
    "1. Multiple elements\n",
    "2. Saving the multiple pages locally for data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Looking at the search results\n",
    "In this case we are interested in \"artificial intelligence\" and will search PBS Newshour for articles containing the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# we need the %22 or \" to ensure that we get the combination artificial intelligence\n",
    "url = 'https://www.pbs.org/newshour/search-results?q=%22artificial%20intelligence%22'\n",
    "\n",
    "# get url\n",
    "page = requests.get(url)\n",
    "\n",
    "# transform to soup\n",
    "soup = BeautifulSoup(page.content, 'html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting multiple elements\n",
    "We are interested in the URLs that link to the individual articles we want to save later. In the previous Notebook you looked at single items but in this case multiple. Luckily, these are quite simple to find and a quick scan reveals we need to use `<h4 class=\"search-result__title\"> ... </h4>` since this element contains the link to the article. BS4 is flexible and you can search within extracted snippets of HTML.\n",
    "\n",
    "First we need to `.find_all()` items with a class. This will return a list of snippets extracted from the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/economy/google-ceo-calls-for-regulation-of-artificial-intelligence\">Google CEO calls for regulation of <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b></a></h4>\n",
      "Google CEO calls for regulation of artificial intelligence\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/health/are-health-care-claims-overblown-about-artificial-intelligence\">Are health care claims overblown about <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b>?</a></h4>\n",
      "Are health care claims overblown about artificial intelligence?\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/how-artificial-intelligence-spotted-every-solar-panel-in-the-u-s\">How <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> spotted every solar panel in the U.S.</a></h4>\n",
      "How artificial intelligence spotted every solar panel in the U.S.\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/could-an-artificial-intelligence-be-considered-a-person-under-the-law\">Could an <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> be considered a person under the law?</a></h4>\n",
      "Could an artificial intelligence be considered a person under the law?\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/to-beat-vegas-bookies-at-the-world-cup-these-statisticians-turned-to-artificial-intelligence\">To beat Vegas bookies at the World Cup, these statisticians turned to <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b></a></h4>\n",
      "To beat Vegas bookies at the World Cup, these statisticians turned to artificial intelligence\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/show/will-artificial-intelligence-help-us-solve-every-problem\">Will <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> help us solve every problem?</a></h4>\n",
      "Will artificial intelligence help us solve every problem?\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/heres-artificial-intelligence-isnt-get-us\">Here's why <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> isn't out to get us</a></h4>\n",
      "Here's why artificial intelligence isn't out to get us\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/google-artificial-intelligence-beats-world-champion-in-first-game-of-go-tournament\">Google <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> beats world champion in first game of Go tournament</a></h4>\n",
      "Google artificial intelligence beats world champion in first game of Go tournament\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/science/google-artificial-intelligence-beats-champion-at-worlds-most-complicated-board-game\">Google <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b> beats champion at world's most complicated board game</a></h4>\n",
      "Google artificial intelligence beats champion at world's most complicated board game\n",
      "<h4 class=\"search-result__title\"><a href=\"https://www.pbs.org/newshour/show/newshour-bookshelf\">Why humanity is essential to the future of <b class=\"search-highlight\">artificial</b> <b class=\"search-highlight\">intelligence</b></a></h4>\n",
      "Why humanity is essential to the future of artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "results = soup.find_all(class_='search-result__title')\n",
    "\n",
    "for res in results:\n",
    "  print(res)\n",
    "  \n",
    "  # you can search in the extracted data by referencing the extracted data\n",
    "  title = res.find('a').get_text()\n",
    "  print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a. Extract the urls and save in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "\n",
    "# code goes here\n",
    "for res in results:\n",
    "  # you can search in the extracted data by referencing the extracted data\n",
    "  url = res.find('a')['href']\n",
    "  url_list.append(url)\n",
    "\n",
    "url_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save the articles in the data folder\n",
    "While retrieving and extracting at the same time is an option it is a less practical one. Saving a file to the disk has the following advantages:\n",
    "1. You do not overuse the website\n",
    "2. If there is an error extracting (for instance the page is slightly different) then you can easily redo without starting from the beginning\n",
    "3. You have an archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use time.sleep() to make the script wait\n",
    "import time\n",
    "\n",
    "# now we iterate through the url list and save the individual pages\n",
    "for url in url_list:\n",
    "  print(\"Retrieving\",url)\n",
    "\n",
    "  # get url\n",
    "  page = requests.get(url)\n",
    "  \n",
    "  # create a sensible filename\n",
    "  filename = url.replace('https://www.pbs.org/newshour/', '').replace('/', '-') + '.html'\n",
    "  destination = './data/' + filename\n",
    "    \n",
    "  with open(destination, 'w') as f:\n",
    "    f.write(page.text)\n",
    "  \n",
    "  # wait two seconds not to overuse the server\n",
    "  time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
