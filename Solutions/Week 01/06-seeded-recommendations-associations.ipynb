{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations based on Frequently Reviewed Together (association rules)\n",
    "For the final part of this assignment, you can turn to 5.4 in the Practical Recommender Systems book (pp 113-127). Read this chapter and [download](https://www.manning.com/downloads/1927) the code accompanied by the book. Explore `association_rules_calculator.py` in the `builder` directory and translate it to this notebook. Falk uses a different infrastructure, but it is pretty simple to adapt this code. We will provide some guidelines below to speed up the process.\n",
    "\n",
    "The steps found in the source code are:\n",
    "1. Opening the data\n",
    "2. Generating the transactions or, in our case reviews\n",
    "3. Calculate the Support Confidence\n",
    "4. Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Opening the data\n",
    "Since we are not using a database but `.csv` files, we can load them into a dataframe. Decide which data is necessary since we look for user A reviewed x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/BX-Book-Ratings-Subset.csv', sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the reviews\n",
    "What we want is a list containing lists of reviews belonging together. In the case of a shopping list, the output we used was\n",
    "`[['eggs','milk','bread'], ['bacon', 'bread'], [...], [...]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df.groupby('User-ID')['ISBN'].apply(list)\n",
    "reviewed = df_reviews.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the Support Confidence\n",
    "This requires some puzzling, but looking at the source code will give you a clear idea. You can reuse the subroutines in the source code and pass along the list containing the reviews belonging together. Play around with the _minimum support_ parameter. Too strict will result in fewer associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code originated from the book Practical Recommender System. \n",
    "# Some minor tweaks to make it work with the current dataset.\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_itemsets_one(reviewed, min_sup=0.01):\n",
    "    N = len(reviewed)\n",
    "    print(N)\n",
    "    temp = defaultdict(int)\n",
    "    one_itemsets = dict()\n",
    "\n",
    "    for items in reviewed:\n",
    "        for item in items:\n",
    "            inx = frozenset({item})\n",
    "            temp[inx] += 1\n",
    "\n",
    "    print(\"temp:\")\n",
    "    i = 0\n",
    "    # remove all items that is not supported.\n",
    "    for key, itemset in temp.items():\n",
    "        #print(f\"{key}, {itemset}, {min_sup}, {min_sup * N}\")\n",
    "        if itemset > min_sup * N:\n",
    "            i = i + 1\n",
    "            one_itemsets[key] = itemset\n",
    "    print(i)\n",
    "    return one_itemsets\n",
    "\n",
    "def calculate_itemsets_two(reviewed, one_itemsets):\n",
    "    two_itemsets = defaultdict(int)\n",
    "\n",
    "    for items in reviewed:\n",
    "        items = list(set(items))  # remove duplications\n",
    "\n",
    "        if (len(items) > 2):\n",
    "            for perm in combinations(items, 2):\n",
    "                if has_support(perm, one_itemsets):\n",
    "                    two_itemsets[frozenset(perm)] += 1\n",
    "        elif len(items) == 2:\n",
    "            if has_support(items, one_itemsets):\n",
    "                two_itemsets[frozenset(items)] += 1\n",
    "    return two_itemsets\n",
    "\n",
    "def calculate_association_rules(one_itemsets, two_itemsets, N):\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    rules = []\n",
    "    for source, source_freq in one_itemsets.items():\n",
    "        for key, group_freq in two_itemsets.items():\n",
    "            if source.issubset(key):\n",
    "                target = key.difference(source)\n",
    "                support = group_freq / N\n",
    "                confidence = group_freq / source_freq\n",
    "                rules.append((timestamp, next(iter(source)), next(iter(target)),\n",
    "                              confidence, support))\n",
    "    return rules\n",
    "\n",
    "def has_support(perm, one_itemsets):\n",
    "  return frozenset({perm[0]}) in one_itemsets and \\\n",
    "    frozenset({perm[1]}) in one_itemsets\n",
    "\n",
    "min_sup = 0.01\n",
    "N = len(reviewed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_itemsets = calculate_itemsets_one(reviewed, min_sup)\n",
    "two_itemsets = calculate_itemsets_two(reviewed, one_itemsets)\n",
    "rules = calculate_association_rules(one_itemsets, two_itemsets, N)\n",
    "\n",
    "# check how many associations are made\n",
    "len(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the results\n",
    "Create a dataframe for the results of step 3. In order to make it work with the current app please make sure the columns are `source;target;support;confidence`. Save the recommendations as `recommendations-seeded-associations.csv` and replace the file in the app directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = []\n",
    "\n",
    "# iterate through results and create data structure containing the results\n",
    "for rule in rules:\n",
    "  association = {\n",
    "    'source':str(rule[1]),\n",
    "    'target':str(rule[2]),\n",
    "    'support':rule[3],\n",
    "    'confidence':rule[4]\n",
    "  }\n",
    "  # append to list\n",
    "  associations.append(association)\n",
    "\n",
    "# create dataframe\n",
    "df_associations = pd.DataFrame(associations) \n",
    "\n",
    "df_associations.to_csv('recommendations-seeded-associations.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
